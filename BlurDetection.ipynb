{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2F8AObaEJwI1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26493,
     "status": "ok",
     "timestamp": 1649545852078,
     "user": {
      "displayName": "Pragya Roy",
      "userId": "05540828895945034913"
     },
     "user_tz": -330
    },
    "id": "2F8AObaEJwI1",
    "outputId": "7b5c65ae-7144-4b45-831a-35db0e305f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RQL2PaJdh-pi",
   "metadata": {
    "id": "RQL2PaJdh-pi"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b42893-d3bf-474f-8a23-6ed591c87755",
   "metadata": {
    "id": "a2b42893-d3bf-474f-8a23-6ed591c87755"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import time\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kFZakClBrDKE",
   "metadata": {
    "id": "kFZakClBrDKE"
   },
   "outputs": [],
   "source": [
    "rootPath = \"./\"\n",
    "# rootPath = \"/gdrive/MyDrive/ICALML/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "NsN2CD0KOrzr",
   "metadata": {
    "id": "NsN2CD0KOrzr"
   },
   "outputs": [],
   "source": [
    "### Define your algorithm here\n",
    "\n",
    "def laplacian(frame):\n",
    "    image = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    val = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bpPC5o47tDnw",
   "metadata": {
    "id": "bpPC5o47tDnw"
   },
   "outputs": [],
   "source": [
    "def HWT(img, threshold = 35):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    Y = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    M, N = Y.shape\n",
    "    \n",
    "    # Crop input image to be 3 divisible by 2\n",
    "    Y = Y[0:int(M/16)*16, 0:int(N/16)*16]\n",
    "    \n",
    "    # Step 1, compute Haar wavelet of input image\n",
    "    LL1,(LH1,HL1,HH1)= pywt.dwt2(Y, 'haar')\n",
    "    # Another application of 2D haar to LL1\n",
    "    LL2,(LH2,HL2,HH2)= pywt.dwt2(LL1, 'haar') \n",
    "    # Another application of 2D haar to LL2\n",
    "    LL3,(LH3,HL3,HH3)= pywt.dwt2(LL2, 'haar')\n",
    "    \n",
    "    # Construct the edge map in each scale Step 2\n",
    "    E1 = np.sqrt(np.power(LH1, 2)+np.power(HL1, 2)+np.power(HH1, 2))\n",
    "    E2 = np.sqrt(np.power(LH2, 2)+np.power(HL2, 2)+np.power(HH2, 2))\n",
    "    E3 = np.sqrt(np.power(LH3, 2)+np.power(HL3, 2)+np.power(HH3, 2))\n",
    "    \n",
    "    M1, N1 = E1.shape\n",
    "\n",
    "    # Sliding window size level 1\n",
    "    sizeM1 = 8\n",
    "    sizeN1 = 8\n",
    "    \n",
    "    # Sliding windows size level 2\n",
    "    sizeM2 = int(sizeM1/2)\n",
    "    sizeN2 = int(sizeN1/2)\n",
    "    \n",
    "    # Sliding windows size level 3\n",
    "    sizeM3 = int(sizeM2/2)\n",
    "    sizeN3 = int(sizeN2/2)\n",
    "    \n",
    "    # Number of edge maps, related to sliding windows size\n",
    "    N_iter = int((M1/sizeM1)*(N1/sizeN1))\n",
    "    \n",
    "    Emax1 = np.zeros((N_iter))\n",
    "    Emax2 = np.zeros((N_iter))\n",
    "    Emax3 = np.zeros((N_iter))\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # Sliding windows index of level 1\n",
    "    x1 = 0\n",
    "    y1 = 0\n",
    "    # Sliding windows index of level 2\n",
    "    x2 = 0\n",
    "    y2 = 0\n",
    "    # Sliding windows index of level 3\n",
    "    x3 = 0\n",
    "    y3 = 0\n",
    "    \n",
    "    # Sliding windows limit on horizontal dimension\n",
    "    Y_limit = N1-sizeN1\n",
    "    \n",
    "    while count < N_iter:\n",
    "        # Get the maximum value of slicing windows over edge maps \n",
    "        # in each level\n",
    "        Emax1[count] = np.max(E1[x1:x1+sizeM1,y1:y1+sizeN1])\n",
    "        Emax2[count] = np.max(E2[x2:x2+sizeM2,y2:y2+sizeN2])\n",
    "        Emax3[count] = np.max(E3[x3:x3+sizeM3,y3:y3+sizeN3])\n",
    "        \n",
    "        # if sliding windows ends horizontal direction\n",
    "        # move along vertical direction and resets horizontal\n",
    "        # direction\n",
    "        if y1 == Y_limit:\n",
    "            x1 = x1 + sizeM1\n",
    "            y1 = 0\n",
    "            \n",
    "            x2 = x2 + sizeM2\n",
    "            y2 = 0\n",
    "            \n",
    "            x3 = x3 + sizeM3\n",
    "            y3 = 0\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "        # windows moves along horizontal dimension\n",
    "        else:\n",
    "                \n",
    "            y1 = y1 + sizeN1\n",
    "            y2 = y2 + sizeN2\n",
    "            y3 = y3 + sizeN3\n",
    "            count += 1\n",
    "    \n",
    "    # Step 3\n",
    "    EdgePoint1 = Emax1 > threshold;\n",
    "    EdgePoint2 = Emax2 > threshold;\n",
    "    EdgePoint3 = Emax3 > threshold;\n",
    "    \n",
    "    # Rule 1 Edge Pojnts\n",
    "    EdgePoint = EdgePoint1 + EdgePoint2 + EdgePoint3\n",
    "    \n",
    "    n_edges = EdgePoint.shape[0]\n",
    "    \n",
    "    # Rule 2 Dirak-Structure or Astep-Structure\n",
    "    DAstructure = (Emax1[EdgePoint] > Emax2[EdgePoint]) * (Emax2[EdgePoint] > Emax3[EdgePoint]);\n",
    "    \n",
    "    # Rule 3 Roof-Structure or Gstep-Structure\n",
    "    \n",
    "    RGstructure = np.zeros((n_edges))\n",
    "\n",
    "    for i in range(n_edges):\n",
    "    \n",
    "        if EdgePoint[i] == 1:\n",
    "        \n",
    "            if Emax1[i] < Emax2[i] and Emax2[i] < Emax3[i]:\n",
    "            \n",
    "                RGstructure[i] = 1\n",
    "                \n",
    "    # Rule 4 Roof-Structure\n",
    "    \n",
    "    RSstructure = np.zeros((n_edges))\n",
    "\n",
    "    for i in range(n_edges):\n",
    "    \n",
    "        if EdgePoint[i] == 1:\n",
    "        \n",
    "            if Emax2[i] > Emax1[i] and Emax2[i] > Emax3[i]:\n",
    "            \n",
    "                RSstructure[i] = 1\n",
    "\n",
    "    # Rule 5 Edge more likely to be in a blurred image \n",
    "\n",
    "    BlurC = np.zeros((n_edges));\n",
    "\n",
    "    for i in range(n_edges):\n",
    "    \n",
    "        if RGstructure[i] == 1 or RSstructure[i] == 1:\n",
    "        \n",
    "            if Emax1[i] < threshold:\n",
    "            \n",
    "                BlurC[i] = 1                        \n",
    "        \n",
    "    # Step 6\n",
    "    Per = np.sum(DAstructure)/np.sum(EdgePoint)\n",
    "    \n",
    "    # Step 7\n",
    "    if (np.sum(RGstructure) + np.sum(RSstructure)) == 0:\n",
    "        \n",
    "        BlurExtent = 100\n",
    "    else:\n",
    "        BlurExtent = np.sum(BlurC) / (np.sum(RGstructure) + np.sum(RSstructure))\n",
    "    \n",
    "    return BlurExtent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26JsH7FaZrUg",
   "metadata": {
    "id": "26JsH7FaZrUg"
   },
   "outputs": [],
   "source": [
    "## Define dictionary of algo with name\n",
    "algorithms = {'laplacian':laplacian,\n",
    "              'HWT':HWT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fMQUtNvrRQ7o",
   "metadata": {
    "id": "fMQUtNvrRQ7o"
   },
   "outputs": [],
   "source": [
    "def processVideo(file,algo):\n",
    "    value = []\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    while(1):\n",
    "        ret,frame = cap.read()\n",
    "        if ret:\n",
    "            val = algorithms[algo](frame)     \n",
    "            value.append(val)\n",
    "        else:\n",
    "            break\n",
    "    return np.min(value),np.mean(value),np.max(value),np.std(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tGEUVdzh1bUE",
   "metadata": {
    "id": "tGEUVdzh1bUE"
   },
   "outputs": [],
   "source": [
    "## Get features\n",
    "def getFeatures(data,types = 'laplacian'):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    time_logs = []\n",
    "    for items in zip(data[\"Filename\"],data[\"Label\"]):\n",
    "        print(\"Processing video:\",items[0])\n",
    "        start = time.time()\n",
    "        res = processVideo(items[0],types)\n",
    "        end = time.time()\n",
    "        X_data.append([res[0],res[1],res[2],res[3]])\n",
    "        y_data.append(items[1])\n",
    "        time_logs.append([end-start])\n",
    "    return X_data,y_data,time_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "FyfkWYycMoRV",
   "metadata": {
    "id": "FyfkWYycMoRV"
   },
   "outputs": [],
   "source": [
    "def trainModel(data,label):\n",
    "    clf = make_pipeline(SVC(kernel = 'linear', gamma='auto'))\n",
    "    clf.fit(data, label)\n",
    "    return clf\n",
    "\n",
    "def trainModelMulti(data,label):\n",
    "    clf = make_pipeline(OneVsRestClassifier(SVC(kernel = 'linear', gamma='auto')))\n",
    "    clf.fit(data, label)\n",
    "    return clf\n",
    "\n",
    "def testModel(model,data,label):\n",
    "    y_pred = model.predict(data)\n",
    "    pr = precision_score(label,y_pred)    \n",
    "    re = recall_score(label,y_pred)\n",
    "    f1 = f1_score(label,y_pred) \n",
    "    acc = balanced_accuracy_score(label,y_pred)\n",
    "    return {'precision':pr,'recall':re,\"F1\":f1,\"acc\":acc}\n",
    "\n",
    "def testModelMulti(model,data,label):\n",
    "    y_pred = model.predict(data)\n",
    "    pr = precision_score(label,y_pred,average=None)    \n",
    "    re = recall_score(label,y_pred,average=None)\n",
    "    f1 = f1_score(label,y_pred,average=None)  \n",
    "    return {'precision':pr,'recall':re,\"F1\":f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CkQ-wzjP9kSa",
   "metadata": {
    "id": "CkQ-wzjP9kSa"
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel(rootPath + \"train.xlsx\")\n",
    "test = pd.read_excel(rootPath + \"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rBXgUukU8R6s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1595280,
     "status": "ok",
     "timestamp": 1649547579161,
     "user": {
      "displayName": "Pragya Roy",
      "userId": "05540828895945034913"
     },
     "user_tz": -330
    },
    "id": "rBXgUukU8R6s",
    "outputId": "87b183a3-ab87-42c0-a9c4-5efafec92ba9"
   },
   "outputs": [],
   "source": [
    "## Train Data\n",
    "X_train,y_train,train_logs = getFeatures(train,'laplacian')\n",
    "pd.DataFrame(X_train,columns=[\"min\",\"mean\",\"max\",\"std\"]).to_csv(rootPath + \"X_train_laplacian.csv\",index=None)\n",
    "pd.DataFrame(y_train,columns=[\"label\"]).to_csv(rootPath + \"y_train_laplacian.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k3tIh-EZ26Oo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 575026,
     "status": "ok",
     "timestamp": 1649548164370,
     "user": {
      "displayName": "Pragya Roy",
      "userId": "05540828895945034913"
     },
     "user_tz": -330
    },
    "id": "k3tIh-EZ26Oo",
    "outputId": "2a4b8d95-5adc-4825-cf65-07373a277a8c"
   },
   "outputs": [],
   "source": [
    "## Test Data\n",
    "X_test,y_test,test_logs = getFeatures(test,'laplacian')\n",
    "pd.DataFrame(X_test,columns=[\"min\",\"mean\",\"max\",\"std\"]).to_csv(rootPath + \"X_test_laplacian.csv\",index=None)\n",
    "pd.DataFrame(y_test,columns=[\"label\"]).to_csv(rootPath + \"y_test_laplacian.csv\",index=None)\n",
    "pd.DataFrame([train_logs,test_logs]).to_csv(rootPath + \"time_laplacian.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "UDXRcrRn_Qzk",
   "metadata": {
    "id": "UDXRcrRn_Qzk"
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(rootPath + \"X_train_laplacian.csv\")\n",
    "X_test = pd.read_csv(rootPath + \"X_test_laplacian.csv\")\n",
    "y_train = pd.read_csv(rootPath + \"y_train_laplacian.csv\").values.reshape(-1)\n",
    "y_test = pd.read_csv(rootPath + \"y_test_laplacian.csv\").values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "uj5UaMObZXOA",
   "metadata": {
    "id": "uj5UaMObZXOA"
   },
   "outputs": [],
   "source": [
    "## Make binary labels\n",
    "y_train1 = np.array(y_train)\n",
    "y_train1[y_train1 > 0] = 1\n",
    "\n",
    "y_test1 = np.array(y_test)\n",
    "y_test1[y_test1 > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4p6gigykZafh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1648150212858,
     "user": {
      "displayName": "DEDHIYA RONAK DINESH",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17898322514602072598"
     },
     "user_tz": -330
    },
    "id": "4p6gigykZafh",
    "outputId": "35394144-55fc-4a67-b1f1-76dbff0957dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8709677419354839,\n",
       " 'recall': 0.9642857142857143,\n",
       " 'F1': 0.9152542372881356,\n",
       " 'acc': 0.6964285714285714}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = trainModel(X_train,y_train1)\n",
    "testModel(model,X_test,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22727021-2708-40c6-ac65-bd21c90ce400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "Q5JuXfmraKLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1648179532931,
     "user": {
      "displayName": "DEDHIYA RONAK DINESH",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17898322514602072598"
     },
     "user_tz": -330
    },
    "id": "Q5JuXfmraKLF",
    "outputId": "7348bdd6-f095-430a-8c19-a63e9baf8ffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8709677419354839,\n",
       " 'recall': 0.9642857142857143,\n",
       " 'F1': 0.9152542372881356,\n",
       " 'acc': 0.6964285714285714}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HWT\n",
    "## Train Data\n",
    "# X_train,y_train,train_logs = getFeatures(train,'HWT')\n",
    "# pd.DataFrame(X_train,columns=[\"min\",\"mean\",\"max\",\"std\"]).to_csv(rootPath + \"X_train_hwt.csv\",index=None)\n",
    "# pd.DataFrame(y_train,columns=[\"label\"]).to_csv(rootPath + \"y_train_hwt.csv\",index=None)\n",
    "# # ## Test Data\n",
    "# X_test,y_test,test_logs = getFeatures(test,'HWT')\n",
    "# pd.DataFrame(X_test,columns=[\"min\",\"mean\",\"max\",\"std\"]).to_csv(rootPath + \"X_test_hwt.csv\",index=None)\n",
    "# pd.DataFrame(y_test,columns=[\"label\"]).to_csv(rootPath + \"y_test_hwt.csv\",index=None)\n",
    "# pd.DataFrame([train_logs,test_logs]).to_csv(rootPath + \"time_hwt.csv\",index=None)\n",
    "## Save features\n",
    "X_train = pd.read_csv(rootPath + \"X_train_hwt.csv\")\n",
    "X_test = pd.read_csv(rootPath + \"X_test_hwt.csv\")\n",
    "y_train = pd.read_csv(rootPath + \"y_train_hwt.csv\").values.reshape(-1)\n",
    "y_test = pd.read_csv(rootPath + \"y_test_hwt.csv\").values.reshape(-1)\n",
    "## Make binary labels\n",
    "y_train1 = np.array(y_train)\n",
    "y_train1[y_train1 > 0] = 1\n",
    "y_test1 = np.array(y_test)\n",
    "y_test1[y_test1 > 0] = 1\n",
    "## Train test SVM model\n",
    "model = trainModel(X_train,y_train1)\n",
    "testModel(model,X_test,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "yImq3TEdK8J-",
   "metadata": {
    "id": "yImq3TEdK8J-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laplacian {'precision': 0.8709677419354839, 'recall': 0.9642857142857143, 'F1': 0.9152542372881356, 'acc': 0.6964285714285714}\n",
      "fft {'precision': 0.8, 'recall': 1.0, 'F1': 0.888888888888889, 'acc': 0.5}\n",
      "hwt {'precision': 0.8709677419354839, 'recall': 0.9642857142857143, 'F1': 0.9152542372881356, 'acc': 0.6964285714285714}\n",
      "modified_laplacian {'precision': 0.8, 'recall': 1.0, 'F1': 0.888888888888889, 'acc': 0.5}\n"
     ]
    }
   ],
   "source": [
    "## Check all methods:\n",
    "output = []\n",
    "methods = [\"laplacian\",\"fft\",\"hwt\",\"modified_laplacian\"]\n",
    "for ext in methods:\n",
    "    X_train = pd.read_csv(rootPath + \"X_train_\" + ext+ \".csv\")\n",
    "    X_test = pd.read_csv(rootPath + \"X_test_\" + ext + \".csv\")\n",
    "    y_train = pd.read_csv(rootPath + \"y_train_\" + ext + \".csv\").values.reshape(-1)\n",
    "    y_test = pd.read_csv(rootPath + \"y_test_\" + ext + \".csv\").values.reshape(-1)\n",
    "    ## Make binary labels\n",
    "    y_train1 = np.array(y_train)\n",
    "    y_train1[y_train1 > 0] = 1\n",
    "    y_test1 = np.array(y_test)\n",
    "    y_test1[y_test1 > 0] = 1\n",
    "    \n",
    "    data = X_train.iloc[:,:]\n",
    "    label = y_train1\n",
    "    ## Train test SVM model\n",
    "    model = make_pipeline(SVC(kernel = 'linear', gamma='auto'))\n",
    "    model.fit(data, label)\n",
    "    \n",
    "    data = X_test.iloc[:,:]\n",
    "    label = y_test1\n",
    "    val = testModel(model,data,label)\n",
    "    output.append(val)\n",
    "    print(ext,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3da84d06-ad7a-4743-826b-a4256e0403ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output,index=methods).to_csv(\"result/svm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1839658-df44-4c72-8f6b-28a84fad0cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     124.596774\n",
       "1     122.967120\n",
       "2     120.067307\n",
       "3     118.074145\n",
       "4     117.785813\n",
       "         ...    \n",
       "85    124.917373\n",
       "86    124.593396\n",
       "87    123.607062\n",
       "88    122.272332\n",
       "89    121.901565\n",
       "Name: min, Length: 90, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SjTPshC2BmAM",
   "metadata": {
    "id": "SjTPshC2BmAM"
   },
   "outputs": [],
   "source": [
    "## Multiclass \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "encoder = OneHotEncoder()\n",
    "model = trainModelMulti(X_train,encoder.fit_transform(y_train).toarray())\n",
    "testModelMulti(model,X_test,encoder.fit_transform(y_test).toarray())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BlurDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
